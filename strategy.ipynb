{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the first part of the project, we establish a performance baseline by implementing a simple, rule-based trading strategy using a **Simple Moving Average (SMA)** crossover on the 80% of our **BTC/USDT** data. This involves calculating short-term and long-term moving averages and generating **buy or sell signals** when these averages cross. We then backtest this strategy on historical data to evaluate its effectiveness by calculating key metrics like **Return on Investment (ROI), Sharpe Ratio, and maximum drawdown.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"crypto_all.csv\")\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "df.dropna(subset=['date'], inplace=True)\n",
    "df.drop_duplicates(subset=['date', 'symbol'], keep='last', inplace=True)\n",
    "\n",
    "btc_data = df[df[\"symbol\"] == \"BTCUSDT\"].copy()\n",
    "btc_data.set_index('date', inplace=True)\n",
    "btc_data.sort_index(inplace=True)\n",
    "\n",
    "# Split the data before doing any strategy calculation.\n",
    "\n",
    "split_point = int(len(btc_data) * 0.8)\n",
    "train_data = btc_data.iloc[:split_point].copy()\n",
    "test_data = btc_data.iloc[split_point:].copy() # This will be used later for ML evaluation\n",
    "\n",
    "print(f\"--- Data successfully split. Using {len(train_data)} records for training. ---\")\n",
    "print(\"\\nTraining Data Head:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nTest Data Head:\")\n",
    "print(test_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the first section we import the necessary libraries, upload the BTC/USDT data and split it into 80/20 sections, because we want to use some of it for a machine learning algorithm later as a test set. \n",
    "\n",
    "* Now in this next section we define our baseline strategy which is based on 40-hour and 100-hour simple moving averages (SMAs). If short SMA is greater than long SMA, it indicates a buy/hold signal, otherwise a sell/wait. After that cumulative returns of the strategy are being evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IMPORTANT: All calculations are now performed on `train_data` ONLY.\n",
    "short_window = 40\n",
    "long_window = 100\n",
    "\n",
    "train_data['short_sma'] = train_data['close'].rolling(window=short_window, min_periods=1).mean()\n",
    "train_data['long_sma'] = train_data['close'].rolling(window=long_window, min_periods=1).mean()\n",
    "\n",
    "slicer = train_data.index[short_window:]\n",
    "train_data.loc[slicer, 'signal'] = np.where(\n",
    "    train_data['short_sma'].loc[slicer] > train_data['long_sma'].loc[slicer], 1, 0\n",
    ")\n",
    "# Forward fill signals for periods before long_window is calculated\n",
    "train_data['signal'].fillna(0, inplace=True)\n",
    "\n",
    "train_data['positions'] = train_data['signal'].diff()\n",
    "\n",
    "# Backtesting on TRAINING Data \n",
    "train_data['returns'] = train_data['close'].pct_change()\n",
    "train_data['strategy_returns'] = train_data['returns'] * train_data['signal'].shift(1)\n",
    "\n",
    "train_data['cumulative_returns'] = (1 + train_data['returns']).cumprod()\n",
    "train_data['cumulative_strategy_returns'] = (1 + train_data['strategy_returns']).cumprod()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this section, we evaluate our results and compare them to a simple buy-and-hold strategy. We evaluate based on the following metrics:\n",
    "\n",
    "    + ROI\n",
    "\n",
    "    + Volatility\n",
    "\n",
    "    + Sharpe Ratio\n",
    "\n",
    "    + Max Drawdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_periods_per_year = 365 * 24\n",
    "\n",
    "print(train_data['cumulative_returns'])\n",
    "\n",
    "roi_buy_hold = (train_data['cumulative_returns'].iloc[-1] - 1) * 100\n",
    "roi_strategy = (train_data['cumulative_strategy_returns'].iloc[-1] - 1) * 100\n",
    "\n",
    "volatility_buy_hold = train_data['returns'].std() * np.sqrt(trading_periods_per_year) * 100\n",
    "volatility_strategy = train_data['strategy_returns'].std() * np.sqrt(trading_periods_per_year) * 100\n",
    "\n",
    "sharpe_ratio_buy_hold = (train_data['returns'].mean() / train_data['returns'].std()) * np.sqrt(trading_periods_per_year) if train_data['returns'].std() != 0 else 0\n",
    "sharpe_ratio_strategy = (train_data['strategy_returns'].mean() / train_data['strategy_returns'].std()) * np.sqrt(trading_periods_per_year) if train_data['strategy_returns'].std() != 0 else 0\n",
    "\n",
    "max_drawdown_strategy = (train_data['cumulative_strategy_returns'] / train_data['cumulative_strategy_returns'].cummax() - 1).min() * 100\n",
    "max_drawdown_buy_hold = (train_data['cumulative_returns'] / train_data['cumulative_returns'].cummax() - 1).min() * 100\n",
    "\n",
    "# Format and print the results in a table \n",
    "print(\"\\n--- IN-SAMPLE PERFORMANCE (on 80% Training Data) ---\")\n",
    "print(f\"{'Strategy':<25} | {'ROI (%)':>10} | {'Volatility (%)':>15} | {'Sharpe Ratio':>15} | {'Max Drawdown (%)':>20}\")\n",
    "print(\"-\" * 95)\n",
    "print(f\"{'Buy and Hold':<25} | {roi_buy_hold:>10.2f} | {volatility_buy_hold:>15.2f} | {sharpe_ratio_buy_hold:>15.2f} | {max_drawdown_buy_hold:>20.2f}\")\n",
    "print(f\"{'SMA Crossover':<25} | {roi_strategy:>10.2f} | {volatility_strategy:>15.2f} | {sharpe_ratio_strategy:>15.2f} | {max_drawdown_strategy:>20.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Based on these metrics, we can clearly see that the SMA strategy is superior to a simple buy-and-hold strategy, as it provides better risk-adjusted returns.\n",
    "\n",
    "* In the latter part, we visualize our signals on a chosen shorter snapshot as well as our overall compounded returns. We can clearly see how our strategy improves upon the naive buy-and-hold approach. To further improve our crypto hedge fund, we will now continue to the second part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualization of TRAINING Results \n",
    "\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-06-30'\n",
    "\n",
    "snapshot_data = train_data.loc[start_date:end_date]\n",
    "\n",
    "print(f\"\\n--- Displaying plot snapshot from {start_date} to {end_date} ---\")\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.plot(snapshot_data['close'], label='Close Price', color='lightblue', alpha=0.9, linewidth=2)\n",
    "ax.plot(snapshot_data['short_sma'], label=f'{short_window}-Day SMA', color='orange', linestyle='--')\n",
    "ax.plot(snapshot_data['long_sma'], label=f'{long_window}-Day SMA', color='purple', linestyle='--')\n",
    "\n",
    "# Plot buy signals from the snapshot data\n",
    "ax.plot(snapshot_data[snapshot_data['positions'] == 1].index,\n",
    "         snapshot_data['short_sma'][snapshot_data['positions'] == 1],\n",
    "         '^', markersize=12, color='g', lw=0, label='Buy Signal')\n",
    "\n",
    "# Plot sell signals from the snapshot data\n",
    "ax.plot(snapshot_data[snapshot_data['positions'] == -1].index,\n",
    "         snapshot_data['short_sma'][snapshot_data['positions'] == -1],\n",
    "         'v', markersize=12, color='r', lw=0, label='Sell Signal')\n",
    "\n",
    "ax.set_title(f'SMA Strategy Snapshot ({start_date} to {end_date})')\n",
    "ax.set_ylabel('Price (USDT)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig, ax2 = plt.subplots(figsize=(15, 7))\n",
    "ax2.plot(train_data['cumulative_returns'], label='Buy and Hold Strategy')\n",
    "ax2.plot(train_data['cumulative_strategy_returns'], label='SMA Crossover Strategy')\n",
    "ax2.set_title('Performance on Training Data')\n",
    "ax2.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second part of the project, we enhance our system by developing and comparing more sophisticated trading strategies against our established baseline. To do this, we implement two distinct models: a machine learning **AI Agent (LightGBM)** and a classical econometric **ARIMA** model.\n",
    "\n",
    "First, we train these models on the initial 80% of the data, using engineered features like **RSI** and **MACD** for the AI Agent. Then, to ensure a realistic and unbiased evaluation, we perform a rigorous **out-of-sample backtest**, deploying the trained models on the remaining 20% of the data that they have never seen before. Finally, we calculate the same key performance metrics (ROI, Sharpe Ratio, Volatility, and Max Drawdown) for these new strategies and compare them directly against the original SMA Crossover and a simple buy-and-hold approach to determine their effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We first import libraries for our AI Agent (LightGBM) and train the model on the 80% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas_ta as ta\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set Global Random Seeds for Reproducibility \n",
    "seed_value = 12345\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "print(f\"Global random seeds set to {seed_value} for reproducibility.\")\n",
    "\n",
    "\n",
    "# Training Phase (on train_data for AI Agent) \n",
    "print(\"\\n--- Phase 1: Training the AI Agent on Training Data ---\")\n",
    "print(train_data.head())\n",
    "\n",
    "train_data['returns'] = train_data['close'].pct_change()\n",
    "train_data['feature_rsi'] = ta.rsi(train_data['close'], length=14)\n",
    "train_data['feature_macd'] = ta.macd(train_data['close'], fast=12, slow=26).iloc[:, 0]\n",
    "train_data['feature_volatility'] = train_data['returns'].rolling(window=21).std()\n",
    "\n",
    "\n",
    "future_period = 5\n",
    "train_data['target'] = (train_data['close'].pct_change(periods=future_period).shift(-future_period) > 0).astype(int)\n",
    "\n",
    "features = [col for col in train_data.columns if 'feature_' in col]\n",
    "model_columns_to_check = features + ['target']\n",
    "train_data.dropna(subset=model_columns_to_check, inplace=True)\n",
    "\n",
    "y_train = train_data['target']\n",
    "X_train = train_data[features]\n",
    "\n",
    "X_train = X_train.iloc[:-future_period]\n",
    "y_train = y_train.iloc[:-future_period]\n",
    "\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(objective='binary', random_state=seed_value)\n",
    "lgbm.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This code block performs the out-of-sample backtest on the 20% of data held out for testing. It evaluates four distinct strategies: \n",
    "    * a simple Buy and Hold\n",
    "    * the rule-based SMA Crossover\n",
    "    * a forecasting ARIMA model\n",
    "    * the predictive AI Agent. \n",
    "* By generating signals and calculating cumulative returns for each on this unseen data, the code provides a direct and unbiased comparison of their real-world performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Phase (on test_data) \n",
    "print(\"\\n--- Phase 2: Evaluating All Strategies on Unseen Test Data ---\")\n",
    "\n",
    "# Prepare a clean base for all test strategies to use\n",
    "base_test_data = test_data.copy()\n",
    "base_test_data['returns'] = base_test_data['close'].pct_change() \n",
    "base_test_data.dropna(subset=['returns'], inplace=True)\n",
    "\n",
    "# Step 1: Backtest Buy and Hold Strategy\n",
    "bh_test_data = base_test_data.copy()\n",
    "bh_test_data['cumulative_returns'] = (1 + bh_test_data['returns']).cumprod()\n",
    "\n",
    "# Step 2: Backtest SMA Crossover Strategy\n",
    "sma_test_data = base_test_data.copy()\n",
    "short_window, long_window = 40, 100\n",
    "sma_test_data['short_sma'] = ta.sma(sma_test_data['close'], length=short_window)\n",
    "sma_test_data['long_sma'] = ta.sma(sma_test_data['close'], length=long_window)\n",
    "sma_test_data.dropna(subset=['short_sma', 'long_sma', 'returns'], inplace=True)\n",
    "sma_test_data['sma_signal'] = np.where(sma_test_data['short_sma'] > sma_test_data['long_sma'], 1, 0)\n",
    "sma_test_data['sma_strategy_returns'] = sma_test_data['returns'] * sma_test_data['sma_signal'].shift(1)\n",
    "sma_test_data['sma_strategy_returns'].fillna(0, inplace=True) \n",
    "sma_test_data['cumulative_sma_strategy_returns'] = (1 + sma_test_data['sma_strategy_returns']).cumprod()\n",
    "\n",
    "# Step 3: Backtest ARIMA Strategy\n",
    "arima_test_data = base_test_data.copy()\n",
    "print(f\"Test set size for ARIMA: {len(arima_test_data)} hours\") \n",
    "print(\"Starting ARIMA walk-forward validation with periodic retraining...\") \n",
    "history = list(train_data['close'])\n",
    "test_prices = list(arima_test_data['close'])\n",
    "predictions = []\n",
    "model_fit = None\n",
    "retrain_frequency = 240\n",
    "for t in range(len(test_prices)):\n",
    "    if t % retrain_frequency == 0 or model_fit is None:\n",
    "        model = ARIMA(history, order=(5,1,0))\n",
    "        model_fit = model.fit()\n",
    "    output = model_fit.forecast()\n",
    "    yhat = output[0]\n",
    "    predictions.append(yhat)\n",
    "    obs = test_prices[t]\n",
    "    history.append(obs)\n",
    "print(\"ARIMA validation complete.\")\n",
    "arima_test_data['arima_forecast'] = predictions\n",
    "arima_test_data['arima_signal'] = np.where(arima_test_data['arima_forecast'].shift(1) > arima_test_data['close'].shift(1), 1, 0) \n",
    "arima_test_data['arima_strategy_returns'] = arima_test_data['returns'] * arima_test_data['arima_signal']\n",
    "arima_test_data['arima_strategy_returns'].fillna(0, inplace=True) \n",
    "arima_test_data['cumulative_arima_strategy_returns'] = (1 + arima_test_data['arima_strategy_returns']).cumprod()\n",
    "\n",
    "# Step 4: Backtest AI Agent Strategy\n",
    "ai_test_data = base_test_data.copy()\n",
    "ai_test_data['feature_rsi'] = ta.rsi(ai_test_data['close'], length=14)\n",
    "ai_test_data['feature_macd'] = ta.macd(ai_test_data['close'], fast=12, slow=26).iloc[:, 0]\n",
    "ai_test_data['feature_volatility'] = ai_test_data['returns'].rolling(window=21).std() \n",
    "ai_test_data.dropna(subset=features, inplace=True)\n",
    "X_test = ai_test_data[features]\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "ai_test_data['ai_signal'] = lgbm.predict(X_test)\n",
    "ai_test_data['ai_strategy_returns'] = ai_test_data['returns'] * ai_test_data['ai_signal'].shift(1) \n",
    "ai_test_data['ai_strategy_returns'].fillna(0, inplace=True) \n",
    "ai_test_data['cumulative_ai_strategy_returns'] = (1 + ai_test_data['ai_strategy_returns']).cumprod()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this next section we evaluate performance of our models to determine if AI-based strategy and econometric model have increased our metrics substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Performance Evaluation (on Test Data)\n",
    "trading_periods_per_year = 365 * 24 \n",
    "\n",
    "roi_bh = (bh_test_data['cumulative_returns'].iloc[-1] - 1) * 100\n",
    "vol_bh = bh_test_data['returns'].std() * np.sqrt(trading_periods_per_year) * 100\n",
    "sharpe_bh = bh_test_data['returns'].mean() / bh_test_data['returns'].std() * np.sqrt(trading_periods_per_year)\n",
    "drawdown_bh = (bh_test_data['cumulative_returns'] / bh_test_data['cumulative_returns'].cummax() - 1).min() * 100\n",
    "\n",
    "roi_sma = (sma_test_data['cumulative_sma_strategy_returns'].iloc[-1] - 1) * 100\n",
    "vol_sma = sma_test_data['sma_strategy_returns'].std() * np.sqrt(trading_periods_per_year) * 100\n",
    "sharpe_sma = sma_test_data['sma_strategy_returns'].mean() / sma_test_data['sma_strategy_returns'].std() * np.sqrt(trading_periods_per_year)\n",
    "drawdown_sma = (sma_test_data['cumulative_sma_strategy_returns'] / sma_test_data['cumulative_sma_strategy_returns'].cummax() - 1).min() * 100\n",
    "\n",
    "roi_arima = (arima_test_data['cumulative_arima_strategy_returns'].iloc[-1] - 1) * 100\n",
    "vol_arima = arima_test_data['arima_strategy_returns'].std() * np.sqrt(trading_periods_per_year) * 100\n",
    "sharpe_arima = arima_test_data['arima_strategy_returns'].mean() / arima_test_data['arima_strategy_returns'].std() * np.sqrt(trading_periods_per_year)\n",
    "drawdown_arima = (arima_test_data['cumulative_arima_strategy_returns'] / arima_test_data['cumulative_arima_strategy_returns'].cummax() - 1).min() * 100\n",
    "\n",
    "roi_ai = (ai_test_data['cumulative_ai_strategy_returns'].iloc[-1] - 1) * 100\n",
    "vol_ai = ai_test_data['ai_strategy_returns'].std() * np.sqrt(trading_periods_per_year) * 100\n",
    "sharpe_ai = ai_test_data['ai_strategy_returns'].mean() / ai_test_data['ai_strategy_returns'].std() * np.sqrt(trading_periods_per_year)\n",
    "drawdown_ai = (ai_test_data['cumulative_ai_strategy_returns'] / ai_test_data['cumulative_ai_strategy_returns'].cummax() - 1).min() * 100\n",
    "\n",
    "\n",
    "print(\"\\n--- OUT-OF-SAMPLE PERFORMANCE COMPARISON (on 20% Test Data) ---\")\n",
    "print(f\"{'Strategy':<25} | {'ROI (%)':>10} | {'Volatility (%)':>15} | {'Sharpe Ratio':>15} | {'Max Drawdown (%)':>20}\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"{'Buy and Hold':<25} | {roi_bh:>10.2f} | {vol_bh:>15.2f} | {sharpe_bh:>15.2f} | {drawdown_bh:>20.2f}\")\n",
    "print(f\"{'SMA Crossover':<25} | {roi_sma:>10.2f} | {vol_sma:>15.2f} | {sharpe_sma:>15.2f} | {drawdown_sma:>20.2f}\")\n",
    "print(f\"{'ARIMA':<25} | {roi_arima:>10.2f} | {vol_arima:>15.2f} | {sharpe_arima:>15.2f} | {drawdown_arima:>20.2f}\")\n",
    "print(f\"{'AI Agent (LightGBM)':<25} | {roi_ai:>10.2f} | {vol_ai:>15.2f} | {sharpe_ai:>15.2f} | {drawdown_ai:>20.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Breakdown**\n",
    "\n",
    "* Best Overall Performer (**AI Agent**): The LightGBM strategy was the most impressive, achieving the highest ROI at 40.57% and the best risk-adjusted returns, as shown by its top-performing Sharpe Ratio of 0.94. \n",
    "\n",
    "* Strong Runner-Up (**ARIMA**): Although ARIMA was the third most profitable strategy, with a strong ROI of 21.40% and a solid Sharpe Ratio, it has offered excellent risk management, minimizing Max Drawdown and Volatility.\n",
    "\n",
    "* Effective Risk Manager (**SMA Crossover**): The SMA Crossover strategy proved its value in risk management. While its ROI was the lowest, it achieved the lowest Volatility, successfully smoothing out returns and reducing risk compared to a simple Buy and Hold approach.\n",
    "\n",
    "* Baseline (**Buy and Hold**): The passive Buy and Hold strategy served as a good baseline but was outperformed by all other active strategies in terms of risk-adjusted returns and drawdown, highlighting the value of a systematic trading approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Strategy': ['Buy and Hold', 'SMA Crossover', 'ARIMA', 'AI Agent (LightGBM)'],\n",
    "    'ROI (%)': [roi_bh, roi_sma, roi_arima, roi_ai],\n",
    "    'Volatility (%)': [vol_bh, vol_sma, vol_arima, vol_ai],\n",
    "    'Sharpe Ratio': [sharpe_bh, sharpe_sma, sharpe_arima, sharpe_ai],\n",
    "    'Max Drawdown (%)': [drawdown_bh, drawdown_sma, drawdown_arima, drawdown_ai]\n",
    "}\n",
    "df_metrics = pd.DataFrame(data)\n",
    "\n",
    "# Invert and Standardize Metrics \n",
    "df_standardized = df_metrics.copy()\n",
    "\n",
    "# Invert metrics where a lower value is better\n",
    "df_standardized['Inv_Volatility'] = 1 / df_standardized['Volatility (%)']\n",
    "df_standardized['Inv_Max_Drawdown'] = 1 / abs(df_standardized['Max Drawdown (%)'])\n",
    "\n",
    "metrics_to_scale = ['ROI (%)', 'Sharpe Ratio', 'Inv_Volatility', 'Inv_Max_Drawdown']\n",
    "\n",
    "# Use StandardScaler for a more linear transformation\n",
    "scaler = StandardScaler()\n",
    "df_standardized[metrics_to_scale] = scaler.fit_transform(df_standardized[metrics_to_scale])\n",
    "min_val = df_standardized[metrics_to_scale].min().min()\n",
    "df_standardized[metrics_to_scale] = df_standardized[metrics_to_scale] - min_val + 0.1\n",
    "\n",
    "\n",
    "labels = ['ROI', 'Sharpe Ratio', '1 / Volatility', '1 / Max Drawdown']\n",
    "num_vars = len(labels)\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1] \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "colors = {\n",
    "    'Buy and Hold': 'C0',\n",
    "    'SMA Crossover': 'C1',\n",
    "    'ARIMA': 'C2',\n",
    "    'AI Agent (LightGBM)': 'C3'\n",
    "}\n",
    "\n",
    "for i, row in df_standardized.iterrows():\n",
    "    strategy_name = row['Strategy']\n",
    "    values = row[metrics_to_scale].values.tolist()\n",
    "    values += values[:1]\n",
    "    color = colors[strategy_name]\n",
    "    \n",
    "    ax.fill(angles, values, color=color, alpha=0.25)\n",
    "    ax.plot(angles, values, color=color, linewidth=2, label=strategy_name)\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels)\n",
    "plt.title('Strategy Performance Comparison (Standardized)', size=20, y=1.1)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight!**\n",
    "* Although the more complex models yielded higher returns, the SMA strategy offered the best risk management. We can try combining these two approaches to create a better strategy in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization (on Aligned Test Data)\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.plot(bh_test_data.index, bh_test_data['cumulative_returns'], label='Buy and Hold')\n",
    "ax.plot(sma_test_data.index, sma_test_data['cumulative_sma_strategy_returns'], label='SMA Crossover Strategy')\n",
    "ax.plot(arima_test_data.index, arima_test_data['cumulative_arima_strategy_returns'], label='ARIMA Strategy')\n",
    "ax.plot(ai_test_data.index, ai_test_data['cumulative_ai_strategy_returns'], label='AI Agent Strategy')\n",
    "ax.set_title('Out-of-Sample Performance Comparison (Aligned Start Date)')\n",
    "ax.set_ylabel('Cumulative Returns')\n",
    "ax.set_xlabel('Date')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training AI-driven and econometric models we clearly see the improvement. Now it's time to expand our hedge fund model to start considering other assets to construct a crypto portfolio. For efficiency we only use 5 other currencies at first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just as in the second part of the project we prepare our data first (this block is identical in 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"crypto_all.csv\")\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "df.drop_duplicates(subset=['date', 'symbol'], keep='last', inplace=True)\n",
    "\n",
    "btc_data = df[df[\"symbol\"] == \"BTCUSDT\"].copy()\n",
    "btc_data.set_index('date', inplace=True)\n",
    "btc_data.sort_index(inplace=True)\n",
    "\n",
    "split_point = int(len(btc_data) * 0.8)\n",
    "train_data_single_asset = btc_data.iloc[:split_point].copy()\n",
    "test_data_single_asset = btc_data.iloc[split_point:].copy()\n",
    "print(f\"Training data runs from {train_data_single_asset.index.min()} to {train_data_single_asset.index.max()}\")\n",
    "print(f\"Test data period defined from {test_data_single_asset.index.min()} to {test_data_single_asset.index.max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now once again we would train our AI Agent using LighGBM. Notice how we only train it using BTCUSDT Data - it would be smarter to use all of the coins in our future portfolio, but we omit it for simplicity now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AI Agent Training\n",
    "print(\"\\n--- Training AI Agent with robust, leak-proof pipeline ---\")\n",
    "training_df = train_data_single_asset.copy()\n",
    "training_df['returns'] = training_df['close'].pct_change()\n",
    "training_df['feature_rsi'] = ta.rsi(training_df['close'], length=14)\n",
    "training_df['feature_macd'] = ta.macd(training_df['close'], fast=12, slow=26).iloc[:, 0]\n",
    "training_df['feature_volatility'] = training_df['returns'].rolling(window=21).std()\n",
    "future_period = 5\n",
    "training_df['target'] = (training_df['close'].pct_change(periods=future_period).shift(-future_period) > 0).astype(int)\n",
    "features = [col for col in training_df.columns if 'feature_' in col]\n",
    "model_columns = features + ['target']\n",
    "training_df.dropna(subset=model_columns, inplace=True)\n",
    "X_train = training_df[features]\n",
    "y_train = training_df['target']\n",
    "lgbm = lgb.LGBMClassifier(objective='binary', random_state=seed_value)\n",
    "lgbm.fit(X_train, y_train)\n",
    "print(\"AI Agent training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now prepare data for the assets in our future portfolio. I am taking the following 5 pairs: BTC/USDT, ETH/USDT, BNB/USDT, DOGE/USDT, LTC/USDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Data Preparation\n",
    "portfolio_assets = ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'DOGEUSDT', 'LTCUSDT']\n",
    "print(f\"\\nPreparing data for portfolio: {portfolio_assets}\")\n",
    "\n",
    "def prepare_portfolio_data(source_df, start_date, end_date, assets, is_returns=False):\n",
    "    portfolio_master = source_df[source_df['symbol'].isin(assets)]\n",
    "    portfolio_period_df = portfolio_master[(portfolio_master['date'] >= start_date) & (portfolio_master['date'] <= end_date)]\n",
    "    if is_returns:\n",
    "        prices_df = portfolio_period_df.pivot(index='date', columns='symbol', values='close')\n",
    "        prices_df.ffill(inplace=True)\n",
    "        returns_df = prices_df.pct_change()\n",
    "        returns_df.fillna(0, inplace=True)\n",
    "        return returns_df\n",
    "    else:\n",
    "        prices_df = portfolio_period_df.pivot_table(index='date', columns='symbol', values=['close', 'high', 'low'])\n",
    "        prices_df.ffill(inplace=True)\n",
    "        prices_df.dropna(inplace=True)\n",
    "        return prices_df\n",
    "\n",
    "train_returns_df = prepare_portfolio_data(df, train_data_single_asset.index.min(), train_data_single_asset.index.max(), portfolio_assets, is_returns=True)\n",
    "test_prices_df_multi = prepare_portfolio_data(df, test_data_single_asset.index.min(), test_data_single_asset.index.max(), portfolio_assets, is_returns=False)\n",
    "test_returns_df = test_prices_df_multi['close'].pct_change().dropna()\n",
    "print(f\"--- Unified portfolio test start date: {test_returns_df.index.min()} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since Bitcoin is the largest, most liquid, and most established cryptocurrency, we set a 70% baseline for it in our portfolio. That way the remaining 30% are used for smaller, higher-risk investments in altcoins, while we guarantee safety and market dominance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this next block we estimate the best static weights for other coins, using a **Monte Carlo** Simulation on training data, testing out 10.000 portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal static weights with BTC >= 70% constraint\n",
    "print(\"\\n--- Finding optimal static weights with BTC >= 70% constraint ---\")\n",
    "mean_returns = train_returns_df.mean()\n",
    "cov_matrix = train_returns_df.cov()\n",
    "num_portfolios = 10000\n",
    "trading_periods_per_year = 365 * 24\n",
    "results = np.zeros((3, num_portfolios))\n",
    "weights_list = []\n",
    "asset_list = list(train_returns_df.columns)\n",
    "btc_index = asset_list.index('BTCUSDT')\n",
    "\n",
    "for i in range(num_portfolios):\n",
    "    btc_weight = np.random.uniform(0.7, 1.0)\n",
    "    remaining_weight = 1.0 - btc_weight\n",
    "    other_weights = np.random.random(len(asset_list) - 1)\n",
    "    other_weights /= np.sum(other_weights) if np.sum(other_weights) > 0 else 1\n",
    "    other_weights *= remaining_weight\n",
    "    weights = np.insert(other_weights, btc_index, btc_weight)\n",
    "    weights_list.append(weights)\n",
    "    \n",
    "    p_return = np.sum(mean_returns * weights) * trading_periods_per_year\n",
    "    p_stddev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix * trading_periods_per_year, weights)))\n",
    "    results[0,i], results[1,i], results[2,i] = p_return, p_stddev, p_return / p_stddev if p_stddev != 0 else 0\n",
    "\n",
    "max_sharpe_idx = np.argmax(results[2])\n",
    "max_sharpe_weights_constrained = weights_list[max_sharpe_idx]\n",
    "print(\"Optimal static weights with constraint found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It's now time to backtest our final strategies and compare them to the Bitcoin-only strategy (from part 1.2). While steps 1a. and 1b. are fairly trivial, **Dynamic Rebalancing** of the AI Portfolio in the step 1c. is being done by calculating RSI, MACD and ATR to create a **Volatility Filter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out-of-Sample Backtesting on Test Data \n",
    "print(\"\\n--- Backtesting all strategies on test data ---\")\n",
    "# 1a. Bitcoin-Only Strategy\n",
    "btc_only_returns = test_returns_df['BTCUSDT']\n",
    "cumulative_btc_returns = (1 + btc_only_returns).cumprod()\n",
    "# 1b. Static MPT Portfolio (with BTC constraint)\n",
    "static_portfolio_returns = test_returns_df.dot(max_sharpe_weights_constrained)\n",
    "cumulative_static_portfolio_returns = (1 + static_portfolio_returns).cumprod()\n",
    "# 1c. Dynamic AI Portfolio (with BTC constraint and Vol Filter)\n",
    "signals_df = pd.DataFrame(index=test_prices_df_multi.index)\n",
    "for asset in asset_list:\n",
    "    asset_test_df = test_prices_df_multi.loc[:, (slice(None), asset)]\n",
    "    asset_test_df.columns = asset_test_df.columns.droplevel(1)\n",
    "    asset_test_df['returns'] = asset_test_df['close'].pct_change()\n",
    "    asset_test_df['feature_rsi'] = ta.rsi(asset_test_df['close'], length=14)\n",
    "    asset_test_df['feature_macd'] = ta.macd(asset_test_df['close'], fast=12, slow=26).iloc[:, 0]\n",
    "    asset_test_df['feature_volatility'] = asset_test_df['returns'].rolling(window=21).std()\n",
    "    asset_test_df['atr'] = ta.atr(asset_test_df['high'], asset_test_df['low'], asset_test_df['close'], length=14)\n",
    "    asset_test_df['volatility_filter'] = (asset_test_df['atr'] / asset_test_df['close']) < 0.04\n",
    "    asset_test_df.dropna(inplace=True)\n",
    "    X_test_asset = asset_test_df[features]\n",
    "    if not X_test_asset.empty:\n",
    "        X_test_asset = X_test_asset[X_train.columns]\n",
    "        asset_test_df['ai_signal'] = lgbm.predict(X_test_asset)\n",
    "        asset_test_df['final_signal'] = np.where((asset_test_df['ai_signal'] == 1) & (asset_test_df['volatility_filter'] == True), 1, 0)\n",
    "        prediction_series = pd.Series(asset_test_df['final_signal'], index=X_test_asset.index)\n",
    "        signals_df[asset] = prediction_series\n",
    "signals_df.ffill(inplace=True); signals_df.fillna(0, inplace=True)\n",
    "dynamic_weights_df = signals_df.shift(1).fillna(0) * max_sharpe_weights_constrained\n",
    "dynamic_portfolio_returns = (test_returns_df * dynamic_weights_df).sum(axis=1)\n",
    "cumulative_dynamic_portfolio_returns = (1 + dynamic_portfolio_returns).cumprod()\n",
    "print(\"Backtesting complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can now finally evaluate our performance using the same metrics as in part 2 of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Performance Evaluation\n",
    "all_results = []\n",
    "def evaluate_performance(name, returns_series, cumulative_returns_series):\n",
    "    trading_periods = 365 * 24\n",
    "    roi = (cumulative_returns_series.iloc[-1] - 1) * 100\n",
    "    vol = returns_series.std() * np.sqrt(trading_periods) * 100\n",
    "    sharpe = (returns_series.mean() * trading_periods) / (returns_series.std() * np.sqrt(trading_periods)) if returns_series.std() != 0 else 0\n",
    "    drawdown = (cumulative_returns_series / cumulative_returns_series.cummax() - 1).min() * 100\n",
    "    return {'Strategy': name, 'ROI (%)': roi, 'Volatility (%)': vol, 'Sharpe Ratio': sharpe, 'Max Drawdown (%)': drawdown}\n",
    "\n",
    "all_results.append(evaluate_performance(\"Bitcoin Only\", btc_only_returns, cumulative_btc_returns))\n",
    "all_results.append(evaluate_performance(\"Static MPT Portfolio (BTC>=70%)\", static_portfolio_returns, cumulative_static_portfolio_returns))\n",
    "all_results.append(evaluate_performance(\"Dynamic AI Portfolio (BTC>=70%)\", dynamic_portfolio_returns, cumulative_dynamic_portfolio_returns))\n",
    "results_df = pd.DataFrame(all_results)\n",
    "print(\"\\n--- OUT-OF-SAMPLE PERFORMANCE COMPARISON ---\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Breakdown**\n",
    "\n",
    "* Best Overall Performer (**Dynamic AI Portfolio**): While its total ROI was a very close second, the Dynamic AI Portfolio was the clear winner in every risk metric. It achieved the highest Sharpe Ratio (0.84), indicating it was the most efficient at generating returns for the risk taken. Crucially, it also had the lowest Volatility and the smallest Max Drawdown, making it the most stable and robust strategy.\n",
    "\n",
    "* Highest Raw Return (**Bitcoin Only**): The passive Bitcoin Only strategy yielded the highest absolute profit with an ROI of 36.23%. However, this came at the cost of significantly higher risk, as it suffered the largest drawdown and second-highest volatility.\n",
    "\n",
    "* Baseline (**The Static MPT Portfolio**) underperformed the other two strategies in this test. The rigid 70% Bitcoin constraint combined with a simple buy-and-hold approach did not improve upon the other methods, resulting in the lowest ROI and Sharpe Ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Visualization\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(cumulative_btc_returns.index, cumulative_btc_returns, label='Bitcoin Only (Buy and Hold)', linestyle=':')\n",
    "plt.plot(cumulative_static_portfolio_returns.index, cumulative_static_portfolio_returns, label='Static MPT Portfolio (BTC>=70%)')\n",
    "plt.plot(cumulative_dynamic_portfolio_returns.index, cumulative_dynamic_portfolio_returns, label='Dynamic AI Portfolio (BTC>=70%)', linewidth=2, linestyle='--')\n",
    "plt.title('Final Strategy Comparison (Out-of-Sample)')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Date')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
